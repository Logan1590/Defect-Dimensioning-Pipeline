Below are descriptions of the available files/folders:

CAD:
-SampleCAD3_Solid3.sldprt: Solidworks part file for the test object


Blender:
-SampleCAD3_Texture_UnrefinedMesh.blend: Base Blender environment with test object. 
-SampleCAD3_Texture_RefinedMesh.blend: Blender environment with denser test object mesh. Was used to generate corresponding .obj and .mtl files (which are necessary for texture generation).
-SampleCAD3_Texture_RefinedMesh_Only1View.png: Texture generated by using only 1 image of the test object 
-SampleCAD3_Texture_RefinedMesh_All6Views.png: Full texture generated by averaging 6 views of the test object 


Images:
-Checkerboard_Images_for_Calibration: contains 6 images that can be used to calculate camera intrinsics or eye-hand calibration
-Images_for_Training_Defect_Segmentation_ML_Model: contains images and corresponding defect masks for training and applying inference
-Images_for_Training_Object_Segmentation_ML_Model: contains images and corresponding test object masks for training and applying inference
-Images_from_Exploratory_Grid_of_Camera_Views: contains images from a grid of views about a reference view specified by X and Y translation as X_Y.jpg, with corresponding defect and object masks (including hole masks to exclude the background region visible through the test object)


Loose Files:
-Keypoint_Mapping_Toy_List_Centered_Test2.json: Stores 2D-3D feature point mapping for the test object for 6 standard views
-Defect_Segmentation_v2_Backup.pth: ML model for defect segmentation created by taking a COCO-trained model and using "Traing_Segmentation_Model_v2.py" to further train on images and masks of test object's defects
-Object_Segmentation_v2.pth: ML model for test object segmentation created by taking a COCO-trained model and using "Traing_Segmentation_Model_v2.py" to further train on images and masks of test object
-environment.yml: Describes virtual environment for running python scripts


Python:
*Utility functions:*
-model_utils_v4: Defines ML model training scheme, including establishing PyTorch dataset, data augmentation transforms, and Mask R-CNN model setup
-Inference_v4_5: Applies trained machine model to segment defects or test object
-visibility_utils_v4: Stores functions used during mesh projection 
-Image_Comparison_v2: Stores functions for segmenting defects by comparing two images 
-Pose_Interpretation_v13: Stores functions for visualizing estimated object pose
-Thresholding_Metholodogy_v8: Visualizes different methods for defining a threshold value for binarization during feature point extraction

*Pipeline Prep:*
-Camera_Distortion_v4: Finds camera matrix and distortion coefficients
-Eye_in_Hand_Calibration_v4: Finds eye-hand calibration matrix 
-Synthetic_to_CAD_mapping_v7: Performs feature point matching between a new image and a reference image. Use this to define the .json file. (Unlike the name suggests, it works between two images, not necessarily an image and a synthetic rendering.)
-Texturing_v9: Generates a texture file (.png) to texture a 3D model in Blender. Required for Model-Based_Defect_Segmentation_v5.5
-Train_Segmentation_Model_v2: Uses model_utils_v4 to train a machine learning model

*Core Modules:*
-ML_Segmentation: Extracts 2D coordinates of feature points (geometric corners) of test object from image
  -v25: All corners found for each method passed to final selection
  -v26: Corner points found by each method are scored and screened before passing to final selection
-pose_estimation: Finds the 6D pose of the test object in an image 
  -v11 uses solvePnPRansac
  -v12 adds pose refinement with solvePnP ITERATIVE based on initial solution from solvePnPRansac
  -v13 adds a new check on feature point matching between new and reference image that filters out pairings whose distance in 2D image space is more than 3 standard deviations beyond the other pairings. 
-Object_Tool_Relative_Perspective_Correction_v7: Finds a new tool position to match the perspective of a reference image
-Model-Based_Defect_Segmentation_v5.5: Renders a 2D projection of a textured CAD model
-Calibration_and_Annotation_v21: Uses functions from scripts above to segment defects and find and annotate their dimensions 


